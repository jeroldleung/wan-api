{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e3333af",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"pretrained_models/Wan2.1-T2V-1.3B/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a55452f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/dev/wan-api/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models from: pretrained_models/Wan2.1-T2V-1.3B//diffusion_pytorch_model.safetensors\n",
      "    model_name: wan_video_dit model_class: WanModel\n",
      "        This model is initialized with extra kwargs: {'has_image_input': False, 'patch_size': [1, 2, 2], 'in_dim': 16, 'dim': 1536, 'ffn_dim': 8960, 'freq_dim': 256, 'text_dim': 4096, 'out_dim': 16, 'num_heads': 12, 'num_layers': 30, 'eps': 1e-06}\n",
      "    The following models are loaded: ['wan_video_dit'].\n",
      "Loading models from: pretrained_models/Wan2.1-T2V-1.3B//models_t5_umt5-xxl-enc-bf16.pth\n",
      "    model_name: wan_video_text_encoder model_class: WanTextEncoder\n",
      "    The following models are loaded: ['wan_video_text_encoder'].\n",
      "Loading models from: pretrained_models/Wan2.1-T2V-1.3B//Wan2.1_VAE.pth\n",
      "    model_name: wan_video_vae model_class: WanVideoVAE\n",
      "    The following models are loaded: ['wan_video_vae'].\n",
      "Using wan_video_text_encoder from pretrained_models/Wan2.1-T2V-1.3B//models_t5_umt5-xxl-enc-bf16.pth.\n",
      "Using wan_video_dit from pretrained_models/Wan2.1-T2V-1.3B//diffusion_pytorch_model.safetensors.\n",
      "Using wan_video_vae from pretrained_models/Wan2.1-T2V-1.3B//Wan2.1_VAE.pth.\n",
      "No wan_video_image_encoder models available.\n",
      "No wan_video_motion_controller models available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffsynth import ModelManager, WanVideoPipeline\n",
    "\n",
    "# Load models\n",
    "model_manager = ModelManager(device=\"cpu\")\n",
    "model_manager.load_models(\n",
    "    [\n",
    "        f\"{path}/diffusion_pytorch_model.safetensors\",\n",
    "        f\"{path}/models_t5_umt5-xxl-enc-bf16.pth\",\n",
    "        f\"{path}/Wan2.1_VAE.pth\",\n",
    "    ],\n",
    "    torch_dtype=torch.float8_e4m3fn,  # You can set `torch_dtype=torch.float8_e4m3fn` to enable FP8 quantization.\n",
    ")\n",
    "pipe = WanVideoPipeline.from_model_manager(model_manager, torch_dtype=torch.bfloat16, device=\"cuda\")\n",
    "pipe.enable_vram_management(num_persistent_param_in_dit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4460db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:20<00:00,  2.80s/it]\n",
      "VAE decoding: 100%|██████████| 9/9 [00:10<00:00,  1.17s/it]\n",
      "Saving video:   0%|          | 0/81 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Saving video: 100%|██████████| 81/81 [00:00<00:00, 127.51it/s]\n"
     ]
    }
   ],
   "source": [
    "from diffsynth import save_video\n",
    "\n",
    "# Text-to-video\n",
    "video = pipe(\n",
    "    prompt=\"纪实摄影风格画面，一只活泼的小狗在绿茵茵的草地上迅速奔跑。小狗毛色棕黄，两只耳朵立起，神情专注而欢快。阳光洒在它身上，使得毛发看上去格外柔软而闪亮。背景是一片开阔的草地，偶尔点缀着几朵野花，远处隐约可见蓝天和几片白云。透视感鲜明，捕捉小狗奔跑时的动感和四周草地的生机。中景侧面移动视角。\",\n",
    "    negative_prompt=\"色调艳丽，过曝，静态，细节模糊不清，字幕，风格，作品，画作，画面，静止，整体发灰，最差质量，低质量，JPEG压缩残留，丑陋的，残缺的，多余的手指，画得不好的手部，画得不好的脸部，畸形的，毁容的，形态畸形的肢体，手指融合，静止不动的画面，杂乱的背景，三条腿，背景人很多，倒着走\",\n",
    "    num_inference_steps=50,\n",
    "    seed=0,\n",
    "    tiled=True,\n",
    "    # TeaCache parameters\n",
    "    tea_cache_l1_thresh=0.05,  # The larger this value is, the faster the speed, but the worse the visual quality.\n",
    "    tea_cache_model_id=\"Wan2.1-T2V-1.3B\",  # Choose one in (Wan2.1-T2V-1.3B, Wan2.1-T2V-14B, Wan2.1-I2V-14B-480P, Wan2.1-I2V-14B-720P).\n",
    ")\n",
    "save_video(video, \"video-1.mp4\", fps=15, quality=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c05a9dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"video-1.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(\"video-1.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
