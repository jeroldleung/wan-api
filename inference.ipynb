{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9438aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/dev/wan-api/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from diffusers import WanPipeline\n",
    "from diffusers.utils import export_to_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b026d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"pretrained_models/Wan2.1-T2V-1.3B-Diffusers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27d30d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:03<00:00,  1.57it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.02it/s]s/it]\n",
      "Loading pipeline components...: 100%|██████████| 5/5 [00:05<00:00,  1.18s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WanPipeline {\n",
       "  \"_class_name\": \"WanPipeline\",\n",
       "  \"_diffusers_version\": \"0.33.1\",\n",
       "  \"_name_or_path\": \"pretrained_models/Wan2.1-T2V-1.3B-Diffusers\",\n",
       "  \"scheduler\": [\n",
       "    \"diffusers\",\n",
       "    \"UniPCMultistepScheduler\"\n",
       "  ],\n",
       "  \"text_encoder\": [\n",
       "    \"transformers\",\n",
       "    \"UMT5EncoderModel\"\n",
       "  ],\n",
       "  \"tokenizer\": [\n",
       "    \"transformers\",\n",
       "    \"T5TokenizerFast\"\n",
       "  ],\n",
       "  \"transformer\": [\n",
       "    \"diffusers\",\n",
       "    \"WanTransformer3DModel\"\n",
       "  ],\n",
       "  \"vae\": [\n",
       "    \"diffusers\",\n",
       "    \"AutoencoderKLWan\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "pipe = WanPipeline.from_pretrained(model_id, torch_dtype=torch.bfloat16)\n",
    "pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a05d270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A cat and a dog baking a cake together in a kitchen. The cat is carefully measuring flour, while the dog is stirring the batter with a wooden spoon. The kitchen is cozy, with sunlight streaming through the window.\"\n",
    "negative_prompt = \"Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards\"\n",
    "num_frames = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "111873ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:21<00:00,  1.62s/it]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'wan-t2v.mp4'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = pipe(prompt=prompt, negative_prompt=negative_prompt, num_frames=num_frames).frames[0]\n",
    "export_to_video(frames, \"wan-t2v.mp4\", fps=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c05a9dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"wan-t2v.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(\"wan-t2v.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
